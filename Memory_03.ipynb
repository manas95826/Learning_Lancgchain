{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPhMWJ8GGCFHa4iTH45cLcO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manas95826/Learning_Langchain/blob/main/Memory_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub, PromptTemplate, LLMChain, ConversationChain\n",
        "from langchain.chains.conversation.memory import (ConversationBufferMemory,\n",
        "                                                  ConversationSummaryMemory,\n",
        "                                                  ConversationBufferWindowMemory,\n",
        "                                                  ConversationKGMemory)"
      ],
      "metadata": {
        "id": "0Glei0hdd--A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "llm=HuggingFaceHub(\n",
        "    huggingfacehub_api_token='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',\n",
        "    repo_id=repo_id,\n",
        "    model_kwargs={\"temperature\": 0.8, \"max_new_tokens\": 512}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Sz0b0__eKuP",
        "outputId": "722cc789-653c-411d-b28e-fc923c7d6b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_buf = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=ConversationBufferMemory()\n",
        ")"
      ],
      "metadata": {
        "id": "tHvliE0TefAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output=conversation_buf(\"I need one question with options on linear equation in two variables.\")\n",
        "response_text = output['response']\n",
        "output\n",
        "\n",
        "# Extract text until \"Human\" appears\n",
        "human_index = response_text.find('Human:')\n",
        "stripped_response = response_text[:human_index].strip()\n",
        "\n",
        "print(stripped_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpBPRitJep49",
        "outputId": "ddd37342-10c6-4f09-c0ab-831d613377f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with those options?\n",
            "AI: To find the solution for x and y, we need to use the method of substitution or elimination. However, since the equation and the given points are in slope-intercept form, we can use the point-slope form of the equation to find the slope of the line and then use the given points to find x and y values.\n",
            "\n",
            "The point-slope form of a linear equation is y - y1 = m(x - x1), where m is the slope and (x1, y1) is a point on the line. Let's find the slope first.\n",
            "\n",
            "Since the points (1, 2) and (-1, 3) are given, we can use the formula:\n",
            "m = (y2 - y1) / (x2 - x1) = (3 - 2) / (-1 - 1) = 1 / -2 = -0.5\n",
            "\n",
            "Now that we have the slope, we can find the x and y values for the given points using the point-slope form:\n",
            "\n",
            "For the point (1, 2), the equation is y - 2 = -0.5(x - 1), and we need to find x. Substituting x = 1 from the given point, we have y - 2 = -0.5(1 - 1), which simplifies to y - 2 = 0, and when we solve for y, we get y = 2. So, x = 1 and y = 2.\n",
            "\n",
            "For the point (-1, 3), the equation is y - 3 = -0.5(x + 1), and we need to find x. Substituting x = -1 from th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output1=conversation_buf(\"Is it A? (2,3)\")\n",
        "response_text = output1['response']\n",
        "\n",
        "# Extract text until \"Human\" appears\n",
        "human_index = response_text.find('Human:')\n",
        "stripped_response = response_text[:human_index].strip()\n",
        "\n",
        "print(stripped_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tjm71qAFesK0",
        "outputId": "35162a3e-5a1a-4fe6-ca22-f212e7f2d458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output2=conversation_buf(\"Oh I added 6+6=13, my bad.\")\n",
        "response_text = output2['response']\n",
        "\n",
        "# Extract text until \"Human\" appears\n",
        "human_index = response_text.find('Human:')\n",
        "stripped_response = response_text[:human_index].strip()\n",
        "\n",
        "print(stripped_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33KMyAbJtfxv",
        "outputId": "9a831ea4-b1c7-44bf-9fd3-ce15f5808a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y0TADH5ppuDl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}